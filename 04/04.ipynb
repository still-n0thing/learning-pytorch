{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.2\n"
     ]
    }
   ],
   "source": [
    "! python --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traning Deep Neural Networks on a GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data.dataloader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MNIST(\n",
    "    root='data/',\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: data/\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: ToTensor()"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img, label = dataset[0]\n",
    "img.shape, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2d0ec80e350>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "x = 145\n",
    "img, label = dataset[x]\n",
    "plt.imshow(img[0], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_indices(n, val_pct):\n",
    "    n_val = int(val_pct * n) # to get a int val\n",
    "    idxs = np.random.permutation(n)\n",
    "    return idxs[n_val:], idxs[:n_val] # training, validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48000 12000\n",
      "Sample val indices: [58127 13119 52465 39738 48613 32527 14468 28412 10175  4408 41066 31041\n",
      " 40067 45963 25061 21617 14459 30725 57327 12498]\n"
     ]
    }
   ],
   "source": [
    "train_indices, val_indices = split_indices(len(dataset), val_pct=0.2)\n",
    "print(len(train_indices), len(val_indices))\n",
    "print(f'Sample val indices: {val_indices[:20]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "\n",
    "# traning sampler and data loader\n",
    "train_sampler = SubsetRandomSampler(train_indices)\n",
    "train_dl = DataLoader(\n",
    "    dataset,\n",
    "    batch_size,\n",
    "    sampler=train_sampler\n",
    ")\n",
    "\n",
    "# validation sampler and data loader\n",
    "valid_sampler = SubsetRandomSampler(val_indices)\n",
    "valid_dl = DataLoader(\n",
    "    dataset,\n",
    "    batch_size,\n",
    "    sampler=valid_sampler\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb.shape = torch.Size([100, 784])\n",
      "yb.shape = torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in train_dl:\n",
    "    xb = xb.view(xb.size(0), -1)\n",
    "    print(f'xb.shape = {xb.shape}')\n",
    "    print(f'yb.shape = {yb.shape}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0000, 0.2000, 0.0000])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = torch.tensor([0, .2, -0.3])\n",
    "F.relu(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MnistModel(nn.Module):\n",
    "    \"\"\"Feedforward neural network with 1 hidden layer\"\"\"\n",
    "    def __init__(self, in_size, hidden_size, out_size):\n",
    "        super().__init__()\n",
    "        # hidden layer\n",
    "        self.linear1 = nn.Linear(in_size, hidden_size)\n",
    "        # output layer\n",
    "        self.linear2 = nn.Linear(hidden_size, out_size)\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        # Flatten the image tensor\n",
    "        xb = xb.view(xb.size(0), -1)\n",
    "        # get intermindate ouput using hidden layer\n",
    "        out = self.linear1(xb)\n",
    "        # apply activation function\n",
    "        out = F.relu(out)\n",
    "        #get predictions using output layer\n",
    "        out = self.linear2(out)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "num_classes = 10\n",
    "\n",
    "model = MnistModel(\n",
    "    in_size=input_size,\n",
    "    hidden_size=32,\n",
    "    out_size=num_classes\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 784])\n",
      "torch.Size([32])\n",
      "torch.Size([10, 32])\n",
      "torch.Size([10])\n"
     ]
    }
   ],
   "source": [
    "for t in model.parameters():\n",
    "    print(t.shape) # stored in transposed format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images.shape = torch.Size([100, 1, 28, 28])\n",
      "labels.shape = torch.Size([100])\n",
      "Loss: 2.2935950756073\n",
      "output.shape: torch.Size([100, 10])\n",
      "Sample outputs: \n",
      "tensor([[ 0.0156, -0.1521,  0.0318, -0.0039, -0.1964,  0.0683, -0.0979,  0.0378,\n",
      "          0.0446,  0.1415],\n",
      "        [ 0.0273, -0.0708,  0.0914, -0.0745, -0.1464,  0.0789, -0.1194, -0.0330,\n",
      "         -0.0257,  0.1714]])\n",
      "Softmax Sample outputs: \n",
      "tensor([[0.1022, 0.0864, 0.1039, 0.1002, 0.0827, 0.1077, 0.0912, 0.1045, 0.1052,\n",
      "         0.1159],\n",
      "        [0.1033, 0.0937, 0.1102, 0.0933, 0.0869, 0.1088, 0.0892, 0.0973, 0.0980,\n",
      "         0.1193]])\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_dl:\n",
    "    print(f'images.shape = {images.shape}')\n",
    "    print(f'labels.shape = {labels.shape}')\n",
    "    outputs = model(images)\n",
    "    loss = F.cross_entropy(outputs, labels)\n",
    "    print(f'Loss: {loss.item()}')\n",
    "    break\n",
    "\n",
    "print(f'output.shape: {outputs.shape}')\n",
    "print(f'Sample outputs: \\n{outputs[:2].data}')\n",
    "print(f'Softmax Sample outputs: \\n{F.softmax(outputs, dim = 1)[:2].data}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_default_device():\n",
    "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
    "    if torch.cuda.is_available():\n",
    "        return torch.device('cuda')\n",
    "    else:\n",
    "        return torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = get_default_device()\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_device(data, device):\n",
    "    \"\"\"Move tensor(s) to choosen device\"\"\"\n",
    "    if isinstance(data, (list, tuple)):\n",
    "        return [to_device(x, device) for x in data]\n",
    "    return data.to(device, non_blocking=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28])\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "for images, labels in train_dl:\n",
    "    print(images.shape)\n",
    "    images = to_device(images, device)\n",
    "    print(images.device)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeviceDataLoader():\n",
    "    \"\"\"Wrap a dataloader to move data to device\"\"\"\n",
    "    def __init__(self, dl, device):\n",
    "        self.dl = dl\n",
    "        self.device = device\n",
    "    \n",
    "    def __iter__(self):\n",
    "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
    "        for b in self.dl:\n",
    "            yield to_device(b, self.device)\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Number of batches\"\"\"\n",
    "        return len(self.dl)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DeviceDataLoader(train_dl, device)\n",
    "valid_dl = DeviceDataLoader(valid_dl, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(480, 120)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dl), len(valid_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xb.device: cuda:0\n",
      "yb: tensor([6, 7, 3, 3, 9, 6, 7, 3, 1, 8, 8, 3, 5, 6, 8, 8, 5, 4, 7, 1, 0, 8, 5, 1,\n",
      "        1, 1, 1, 9, 4, 4, 6, 1, 0, 6, 3, 1, 8, 4, 8, 6, 0, 8, 9, 2, 3, 7, 0, 0,\n",
      "        3, 3, 1, 7, 6, 1, 3, 0, 2, 0, 8, 8, 6, 7, 1, 6, 4, 1, 9, 1, 0, 3, 3, 1,\n",
      "        9, 0, 6, 9, 6, 0, 9, 5, 7, 9, 2, 6, 5, 7, 5, 6, 9, 1, 0, 3, 9, 7, 8, 8,\n",
      "        0, 7, 2, 3], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for xb, yb in valid_dl:\n",
    "    print(f'xb.device: {xb.device}')\n",
    "    print(f'yb: {yb}')\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_batch(model, loss_func, xb, yb, opt=None, metric=None):\n",
    "    # Generate Predictions\n",
    "    preds = model(xb)\n",
    "    # Calculate Loss \n",
    "    loss = loss_func(preds, yb)\n",
    "\n",
    "    if opt is not None:\n",
    "        # Compute Graditent \n",
    "        loss.backward()\n",
    "        # Update parameters\n",
    "        opt.step()\n",
    "        # Reset Gradient\n",
    "        opt.zero_grad()\n",
    "\n",
    "    metric_result = None\n",
    "    if metric is not None:\n",
    "        # Compute the ,etric\n",
    "        metric_result = metric(preds, yb)\n",
    "\n",
    "    return loss.item(), len(xb), metric_result\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, loss_fn, valid_dl, metric=None):\n",
    "    with torch.no_grad():\n",
    "        # Pass each batch through the model\n",
    "        results = [loss_batch(model, loss_fn, xb, yb, metric=metric)\n",
    "                   for xb, yb in valid_dl]\n",
    "        # Separate losses, counts and metrics\n",
    "        losses, nums, metrics = zip(*results)\n",
    "        # Total size of the dataset \n",
    "        total = np.sum(nums)\n",
    "        # Avg. loss across batches\n",
    "        avg_loss = np.sum(np.multiply(losses, nums)) / total\n",
    "        avg_metric = None\n",
    "        if metric is not None:\n",
    "            # Avg. of metric acros batches\n",
    "            avg_metric = np.sum(np.multiply(metrics, nums)) / total\n",
    "    return avg_loss, total, avg_metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(epochs, lr, model, loss_fn, train_dl, valid_dl, metric=None, opt_fn=None):\n",
    "    losses, metrics = [], []\n",
    "\n",
    "    # Instantiate the optimizer\n",
    "    if opt_fn is None: opt_fn = torch.optim.SGD\n",
    "    opt = opt_fn(model.parameters(), lr=lr)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        # Traning\n",
    "        for xb, yb in train_dl:\n",
    "            loss, _, _ = loss_batch(model, loss_fn, xb, yb, opt)\n",
    "\n",
    "        # Evalution\n",
    "        result = evaluate(model, loss_fn, valid_dl, metric)\n",
    "        val_loss, total, val_metric = result\n",
    "\n",
    "        # Record te loss & metric\n",
    "        losses.append(val_loss)\n",
    "        metrics.append(val_metric)\n",
    "\n",
    "        # Print Progress\n",
    "        if metric is None:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {val_loss:.4f}')\n",
    "        else:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {val_loss:.4f}, {metric.__name__}: {val_metric:.4f}')\n",
    "    return losses, metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(outputs, labels):\n",
    "    _, preds = torch.max(outputs, dim=1)\n",
    "    return torch.sum(preds == labels).item() / len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MnistModel(\n",
       "  (linear1): Linear(in_features=784, out_features=32, bias=True)\n",
       "  (linear2): Linear(in_features=32, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = MnistModel(input_size, hidden_size=32, out_size=num_classes)\n",
    "to_device(model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.3245, Accuracy: 0.0701\n"
     ]
    }
   ],
   "source": [
    "val_loss, total, val_acc = evaluate(\n",
    "    model, F.cross_entropy, valid_dl, metric=accuracy\n",
    ")\n",
    "print(f'Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.2145, accuracy: 0.9332\n",
      "Epoch [2/5], Loss: 0.1541, accuracy: 0.9527\n",
      "Epoch [3/5], Loss: 0.1369, accuracy: 0.9577\n",
      "Epoch [4/5], Loss: 0.1403, accuracy: 0.9589\n",
      "Epoch [5/5], Loss: 0.1345, accuracy: 0.9613\n"
     ]
    }
   ],
   "source": [
    "losses1, metrics1 = fit(5, 0.5, model, F.cross_entropy, train_dl, valid_dl, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.1091, accuracy: 0.9677\n",
      "Epoch [2/5], Loss: 0.1090, accuracy: 0.9674\n",
      "Epoch [3/5], Loss: 0.1085, accuracy: 0.9667\n",
      "Epoch [4/5], Loss: 0.1084, accuracy: 0.9676\n",
      "Epoch [5/5], Loss: 0.1063, accuracy: 0.9677\n"
     ]
    }
   ],
   "source": [
    "losses2, metrics2 = fit(5, 0.1, model, F.cross_entropy, train_dl, valid_dl, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Accuracy vs No. of epochs')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Replace these values with your results\n",
    "accuracies = [val_acc] + metrics1 + metrics2\n",
    "plt.plot(accuracies, '-x')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.title('Accuracy vs No. of epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.07008333333333333,\n",
       " 0.9331666666666667,\n",
       " 0.95275,\n",
       " 0.95775,\n",
       " 0.9589166666666666,\n",
       " 0.96125,\n",
       " 0.96775,\n",
       " 0.9674166666666667,\n",
       " 0.96675,\n",
       " 0.9675833333333334,\n",
       " 0.9676666666666667]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracies"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f24e713387d3c3f1338d96f5f36f4cc155a8d1a9289315c4528c03132d21f819"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
